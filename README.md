# Sori (소리) - Contextual Interpreter

**Sori**는 청각 장애인을 위한 실시간 대화 및 환경 소리 비서 안드로이드 애플리케이션입니다. 주변의 소리를 시각화하여 보여주고, 대화 내용을 실시간 자막과 감정 분석으로 제공하여 원활한 소통을 돕습니다.

## 📱 주요 기능

### 1. 환경 소리 모드 (Environment Sound Mode)
- **소리 시각화**: 주변 소리의 방향과 거리를 레이더 형태로 시각화하여 보여줍니다.
- **위험 알림**: 사이렌, 경적 등 위험한 소리가 감지되면 붉은색 경고와 함께 "긴급" 알림을 표시합니다.
- **실시간 목록**: 감지된 소리의 종류, 발생 시간, 방향 정보를 리스트로 제공합니다.

### 2. 음성 인식 모드 (Voice Recognition Mode)
- **실시간 자막**: 상대방의 말을 실시간으로 텍스트로 변환하여 보여줍니다.
- **감정 분석**: 대화 내용에 담긴 감정(긍정, 부정, 중립)을 분석하여 태그로 표시합니다.
- **자동 스크롤**: 새로운 대화가 입력되면 자동으로 최신 메시지로 스크롤됩니다.

## 🛠 기술 스택

- **Language**: Kotlin
- **UI Framework**: Jetpack Compose
- **Architecture**: MVVM (Model-View-ViewModel)
- **Build System**: Gradle (Kotlin DSL)
- **Minimum SDK**: 24
- **Target SDK**: 36

## 🚀 실행 방법

1.  **프로젝트 열기**: Android Studio에서 프로젝트 루트 폴더(`Sori1`)를 엽니다.
2.  **Gradle 동기화**: `File > Sync Project with Gradle Files`를 클릭하여 의존성을 다운로드합니다.
3.  **앱 실행**: 에뮬레이터 또는 실제 기기를 연결하고 `Run` 버튼(▶)을 클릭합니다.

## ℹ️ 참고 사항 (프로토타입)

현재 버전은 **프로토타입**으로, 실제 AI 모델 대신 **Mock Data(가상 데이터)**를 사용하여 동작 시나리오를 시연합니다.

- **환경 소리**: `SoundRepository`에서 2~5초 간격으로 가상의 소리 이벤트(초인종, 사이렌 등)를 생성합니다.
- **음성 인식**: `ConversationRepository`에서 2초 간격으로 가상의 대화 스크립트를 재생합니다.
